{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_df shape = (1567, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 12:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-07-19 13:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 14:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 15:22:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                Date\n",
       "0     -1 2008-07-19 11:55:00\n",
       "1     -1 2008-07-19 12:32:00\n",
       "2      1 2008-07-19 13:17:00\n",
       "3     -1 2008-07-19 14:43:00\n",
       "4     -1 2008-07-19 15:22:00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv('data/secom_labels.data', sep=' ', header = None)\n",
    "labels_df.columns = ['Label', 'Date']\n",
    "labels_df['Date'] = pd.to_datetime(labels_df['Date'], format = \"%d/%m/%Y %H:%M:%S\")\n",
    "print('labels_df shape = {}'.format(labels_df.shape))\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bccff68198>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAUEklEQVR4nO3dcayd9X3f8fdndkNJ3AQzmivLdmev8tIaaKZwx1i7VdejG04axUwqkjNavAzJasaybKJaoJXGH5M1oo1tDRmprIBwFAvPo9nsrSMrcnfHpkIYpEmMoRQ3MMfBxUtJaC6NaE2/++M8SGfmmnvuOeeem3t/75d0dZ7ze37P8/t9r63Pefw75zxOVSFJasOfW+4JSJImx9CXpIYY+pLUEENfkhpi6EtSQ9Yu9wQWctlll9WWLVuGOvbVV1/lHe94x3gn9H3OmtvQWs2t1Quj1/zkk09+q6p++Pz27/vQ37JlC0888cRQx87OzjIzMzPeCX2fs+Y2tFZza/XC6DUn+T/ztbu8I0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDfm+/0buKI5/8xX+3m2/MfFxX7jzZyc+piQNwit9SWqIoS9JDTH0Jakhhr4kNWTB0E9yX5KzSZ6aZ98vJakkl/W13Z7kZJJnk1zX135VkuPdvk8lyfjKkCQNYpAr/fuBnec3JtkM/C3gVF/bdmA3cHl3zD1J1nS7PwPsBbZ1P286pyRpaS0Y+lX1CPDyPLv+DfBPgepr2wUcqqrXqup54CRwdZINwDur6tGqKuBzwPUjz16StChDrekn+RDwzar66nm7NgLf6Ht+umvb2G2f3y5JmqBFfzkryduBXwH+9ny752mrt2i/0Bh76S0FMTU1xezs7GKnCcDUxXDrleeGOnYUw853HObm5pZ1/OVgzatfa/XC0tU8zDdyfxTYCny1ey92E/DlJFfTu4Lf3Nd3E/Bi175pnvZ5VdV+YD/A9PR0Dfv/RN598Ah3HZ/8l45fuHFm4mO+wf9LtA2t1dxavbB0NS96eaeqjlfVu6tqS1VtoRfo76uqPwCOAruTXJRkK703bB+vqjPAd5Nc031q5ybgyPjKkCQNYpCPbD4APAq8J8npJDdfqG9VnQAOA08DXwRuqarXu90fBT5L783d3wceGnHukqRFWnDto6o+vMD+Lec93wfsm6ffE8AVi5yfJGmM/EauJDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IasmDoJ7kvydkkT/W1/cskv5vka0n+Y5JL+vbdnuRkkmeTXNfXflWS492+TyXJ+MuRJL2VQa707wd2ntf2MHBFVf0E8HvA7QBJtgO7gcu7Y+5JsqY75jPAXmBb93P+OSVJS2zB0K+qR4CXz2v7zao61z19DNjUbe8CDlXVa1X1PHASuDrJBuCdVfVoVRXwOeD6cRUhSRrM2jGc4+8D/77b3kjvReANp7u2P+22z2+fV5K99P5VwNTUFLOzs0NNbOpiuPXKcwt3HLNh5zsOc3Nzyzr+crDm1a+1emHpah4p9JP8CnAOOPhG0zzd6i3a51VV+4H9ANPT0zUzMzPU/O4+eIS7jo/jdW1xXrhxZuJjvmF2dpZhf18rlTWvfq3VC0tX89CJmGQP8EHg2m7JBnpX8Jv7um0CXuzaN83TLkmaoKE+splkJ/AJ4ENV9cd9u44Cu5NclGQrvTdsH6+qM8B3k1zTfWrnJuDIiHOXJC3Sglf6SR4AZoDLkpwG7qD3aZ2LgIe7T14+VlW/WFUnkhwGnqa37HNLVb3eneqj9D4JdDHwUPcjSZqgBUO/qj48T/O9b9F/H7BvnvYngCsWNTtJ0lj5jVxJaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIQuGfpL7kpxN8lRf26VJHk7yXPe4vm/f7UlOJnk2yXV97VclOd7t+1S6/1FdkjQ5g1zp3w/sPK/tNuBYVW0DjnXPSbId2A1c3h1zT5I13TGfAfYC27qf888pSVpiC4Z+VT0CvHxe8y7gQLd9ALi+r/1QVb1WVc8DJ4Grk2wA3llVj1ZVAZ/rO0aSNCFrhzxuqqrOAFTVmSTv7to3Ao/19Tvdtf1pt31++7yS7KX3rwKmpqaYnZ0dbpIXw61Xnhvq2FEMO99xmJubW9bxl4M1r36t1QtLV/OwoX8h863T11u0z6uq9gP7Aaanp2tmZmaoydx98Ah3HR93iQt74caZiY/5htnZWYb9fa1U1rz6tVYvLF3Nw35656VuyYbu8WzXfhrY3NdvE/Bi175pnnZJ0gQNG/pHgT3d9h7gSF/77iQXJdlK7w3bx7uloO8muab71M5NfcdIkiZkwbWPJA8AM8BlSU4DdwB3AoeT3AycAm4AqKoTSQ4DTwPngFuq6vXuVB+l90mgi4GHuh9J0gQtGPpV9eEL7Lr2Av33AfvmaX8CuGJRs5MkjZXfyJWkhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaMlLoJ/knSU4keSrJA0l+MMmlSR5O8lz3uL6v/+1JTiZ5Nsl1o09fkrQYQ4d+ko3APwKmq+oKYA2wG7gNOFZV24Bj3XOSbO/2Xw7sBO5Jsma06UuSFmPU5Z21wMVJ1gJvB14EdgEHuv0HgOu77V3Aoap6raqeB04CV484viRpEYYO/ar6JvCvgFPAGeCVqvpNYKqqznR9zgDv7g7ZCHyj7xSnuzZJ0oSsHfbAbq1+F7AV+A7wH5L8/FsdMk9bXeDce4G9AFNTU8zOzg41x6mL4dYrzw117CiGne84zM3NLev4y8GaV7/W6oWlq3no0Ad+Bni+qv4vQJIvAD8JvJRkQ1WdSbIBONv1Pw1s7jt+E73loDepqv3AfoDp6emamZkZaoJ3HzzCXcdHKXE4L9w4M/Ex3zA7O8uwv6+VyppXv9bqhaWreZQ1/VPANUneniTAtcAzwFFgT9dnD3Ck2z4K7E5yUZKtwDbg8RHGlyQt0tCXwVX1pSQPAl8GzgG/Q+/qfB1wOMnN9F4Ybuj6n0hyGHi6639LVb0+4vwlSYsw0tpHVd0B3HFe82v0rvrn678P2DfKmJKk4fmNXElqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNWSk0E9ySZIHk/xukmeS/LUklyZ5OMlz3eP6vv63JzmZ5Nkk140+fUnSYox6pf+rwBer6seA9wLPALcBx6pqG3Cse06S7cBu4HJgJ3BPkjUjji9JWoShQz/JO4GfBu4FqKo/qarvALuAA123A8D13fYu4FBVvVZVzwMngauHHV+StHipquEOTP4ysB94mt5V/pPAx4FvVtUlff2+XVXrk3waeKyqPt+13ws8VFUPznPuvcBegKmpqasOHTo01BzPvvwKL31vqENHcuXGd01+0M7c3Bzr1q1btvGXgzWvfq3VC6PXvGPHjieravr89rUjzGkt8D7gY1X1pSS/SreUcwGZp23eV5yq2k/vBYXp6emamZkZaoJ3HzzCXcdHKXE4L9w4M/Ex3zA7O8uwv6+VyppXv9bqhaWreZQ1/dPA6ar6Uvf8QXovAi8l2QDQPZ7t67+57/hNwIsjjC9JWqShQ7+q/gD4RpL3dE3X0lvqOQrs6dr2AEe67aPA7iQXJdkKbAMeH3Z8SdLijbr28THgYJK3AV8HPkLvheRwkpuBU8ANAFV1Islhei8M54Bbqur1EceXJC3CSKFfVV8B3vRGAb2r/vn67wP2jTKmJGl4fiNXkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JasjIoZ9kTZLfSfJfuueXJnk4yXPd4/q+vrcnOZnk2STXjTq2JGlxxnGl/3Hgmb7ntwHHqmobcKx7TpLtwG7gcmAncE+SNWMYX5I0oJFCP8km4GeBz/Y17wIOdNsHgOv72g9V1WtV9TxwErh6lPElSYuTqhr+4ORB4F8APwT8UlV9MMl3quqSvj7frqr1ST4NPFZVn+/a7wUeqqoH5znvXmAvwNTU1FWHDh0aan5nX36Fl7431KEjuXLjuyY/aGdubo5169Yt2/jLwZpXv9bqhdFr3rFjx5NVNX1++9phT5jkg8DZqnoyycwgh8zTNu8rTlXtB/YDTE9P18zMIKd/s7sPHuGu40OXOLQXbpyZ+JhvmJ2dZdjf10plzatfa/XC0tU8SiL+FPChJB8AfhB4Z5LPAy8l2VBVZ5JsAM52/U8Dm/uO3wS8OML4kqRFGnpNv6pur6pNVbWF3hu0v1VVPw8cBfZ03fYAR7rto8DuJBcl2QpsAx4feuaSpEVbirWPO4HDSW4GTgE3AFTViSSHgaeBc8AtVfX6EowvSbqAsYR+Vc0Cs932HwLXXqDfPmDfOMaUJC2e38iVpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGjJ06CfZnOS/J3kmyYkkH+/aL03ycJLnusf1fcfcnuRkkmeTXDeOAiRJgxvlSv8ccGtV/ThwDXBLku3AbcCxqtoGHOue0+3bDVwO7ATuSbJmlMlLkhZn6NCvqjNV9eVu+7vAM8BGYBdwoOt2ALi+294FHKqq16rqeeAkcPWw40uSFi9VNfpJki3AI8AVwKmquqRv37eran2STwOPVdXnu/Z7gYeq6sF5zrcX2AswNTV11aFDh4aa19mXX+Gl7w116Eiu3PiuyQ/amZubY926dcs2/nKw5tWvtXph9Jp37NjxZFVNn9++dqRZAUnWAb8O/OOq+qMkF+w6T9u8rzhVtR/YDzA9PV0zMzNDze3ug0e46/jIJS7aCzfOTHzMN8zOzjLs72ulsubVr7V6YelqHunTO0l+gF7gH6yqL3TNLyXZ0O3fAJzt2k8Dm/sO3wS8OMr4kqTFGeXTOwHuBZ6pqn/dt+sosKfb3gMc6WvfneSiJFuBbcDjw44vSVq8UdY+fgr4BeB4kq90bb8M3AkcTnIzcAq4AaCqTiQ5DDxN75M/t1TV6yOML0lapKFDv6r+F/Ov0wNce4Fj9gH7hh1TkjQav5ErSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1Jasjk70YmSSvIltt+Y1nGvX/nO5bkvF7pS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDZl46CfZmeTZJCeT3Dbp8SWpZRMN/SRrgH8HvB/YDnw4yfZJzkGSWjbpK/2rgZNV9fWq+hPgELBrwnOQpGZN+tbKG4Fv9D0/DfzV8zsl2Qvs7Z7OJXl2yPEuA7415LFDyycnPeL/Z1lqXmbWvPq1Vi87PjlyzX9hvsZJh37maas3NVTtB/aPPFjyRFVNj3qelcSa29Baza3VC0tX86SXd04Dm/uebwJenPAcJKlZkw79/w1sS7I1yduA3cDRCc9Bkpo10eWdqjqX5B8C/w1YA9xXVSeWcMiRl4hWIGtuQ2s1t1YvLFHNqXrTkrokaZXyG7mS1BBDX5IasipCf6FbO6TnU93+ryV533LMc1wGqPfGrs6vJfntJO9djnmO06C370jyV5K8nuTnJjm/pTBIzUlmknwlyYkk/2PScxy3Af5uvyvJf07y1a7mjyzHPMclyX1JziZ56gL7x59dVbWif+i9Ifz7wF8E3gZ8Fdh+Xp8PAA/R+57ANcCXlnveS1zvTwLru+33r+R6B625r99vAf8V+LnlnvcE/pwvAZ4GfqR7/u7lnvcEav5l4JPd9g8DLwNvW+65j1DzTwPvA566wP6xZ9dquNIf5NYOu4DPVc9jwCVJNkx6omOyYL1V9dtV9e3u6WP0vg+xkg16+46PAb8OnJ3k5JbIIDX/XeALVXUKoKpWet2D1FzADyUJsI5e6J+b7DTHp6oeoVfDhYw9u1ZD6M93a4eNQ/RZKRZby830rhRWsgVrTrIR+DvAr01wXktpkD/nvwSsTzKb5MkkN01sdktjkJo/Dfw4vS91Hgc+XlV/NpnpLYuxZ9ekb8OwFAa5tcNAt39YIQauJckOeqH/15d0RktvkJr/LfCJqnq9dxG44g1S81rgKuBa4GLg0SSPVdXvLfXklsggNV8HfAX4m8CPAg8n+Z9V9UdLPbllMvbsWg2hP8itHVbT7R8GqiXJTwCfBd5fVX84obktlUFqngYOdYF/GfCBJOeq6j9NZopjN+jf629V1avAq0keAd4LrNTQH6TmjwB3Vm/B+2SS54EfAx6fzBQnbuzZtRqWdwa5tcNR4KbunfBrgFeq6sykJzomC9ab5EeALwC/sIKv+votWHNVba2qLVW1BXgQ+AcrOPBhsL/XR4C/kWRtkrfTu2PtMxOe5zgNUvMpev+yIckU8B7g6xOd5WSNPbtW/JV+XeDWDkl+sdv/a/Q+zfEB4CTwx/SuFlakAev9Z8CfB+7prnzP1Qq+Q+GANa8qg9RcVc8k+SLwNeDPgM9W1bwf/VsJBvxz/ufA/UmO01v6+ERVrdhbLid5AJgBLktyGrgD+AFYuuzyNgyS1JDVsLwjSRqQoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5Ia8v8ADoR0nrVaOvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_df['Label'] = labels_df['Label'].apply(lambda x: 0 if x == -1 else 1)\n",
    "labels_df['Label'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-07-19</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-07-20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-07-21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-07-22</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-07-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Sum  Count\n",
       "0 2008-07-19    3     12\n",
       "1 2008-07-20    0      1\n",
       "2 2008-07-21    1      2\n",
       "3 2008-07-22    0      6\n",
       "4 2008-07-23    0      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_sum = labels_df['Label'].groupby(labels_df['Date'].dt.date).sum().reset_index()\n",
    "label_count = labels_df['Label'].groupby(labels_df['Date'].dt.date).count().reset_index()\n",
    "label_day = pd.merge(label_sum, label_count, on='Date')\n",
    "label_day.columns = ['Date', 'Sum', 'Count']\n",
    "label_day['Date'] = pd.to_datetime(label_day['Date'])\n",
    "label_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure with shared X axis\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, figsize = (15,7))\n",
    "\n",
    "# Remove horizontal space between axes\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "# Set the width of the bars to be 1 day\n",
    "#width = np.timedelta64(1, 'D')\n",
    "\n",
    "# Plot the Sum of fails per day and count of entries per day\n",
    "axs[0].bar(label_day['Date'], label_day['Sum'], color = 'red')\n",
    "axs[1].bar(label_day['Date'], label_day['Count'], color = 'blue')\n",
    "axs[0].set_ylabel('Total Fails per day')\n",
    "axs[1].set_ylabel('Total Count of data per day')\n",
    "axs[1].set_xlabel('Date');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_df shape = (1567, 590)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>...</th>\n",
       "      <th>x_580</th>\n",
       "      <th>x_581</th>\n",
       "      <th>x_582</th>\n",
       "      <th>x_583</th>\n",
       "      <th>x_584</th>\n",
       "      <th>x_585</th>\n",
       "      <th>x_586</th>\n",
       "      <th>x_587</th>\n",
       "      <th>x_588</th>\n",
       "      <th>x_589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x_0      x_1        x_2        x_3     x_4    x_5       x_6     x_7  \\\n",
       "0  3030.93  2564.00  2187.7333  1411.1265  1.3602  100.0   97.6133  0.1242   \n",
       "1  3095.78  2465.14  2230.4222  1463.6606  0.8294  100.0  102.3433  0.1247   \n",
       "2  2932.61  2559.94  2186.4111  1698.0172  1.5102  100.0   95.4878  0.1241   \n",
       "3  2988.72  2479.90  2199.0333   909.7926  1.3204  100.0  104.2367  0.1217   \n",
       "4  3032.24  2502.87  2233.3667  1326.5200  1.5334  100.0  100.3967  0.1235   \n",
       "\n",
       "      x_8     x_9  ...   x_580     x_581   x_582   x_583   x_584    x_585  \\\n",
       "0  1.5005  0.0162  ...     NaN       NaN  0.5005  0.0118  0.0035   2.3630   \n",
       "1  1.4966 -0.0005  ...  0.0060  208.2045  0.5019  0.0223  0.0055   4.4447   \n",
       "2  1.4436  0.0041  ...  0.0148   82.8602  0.4958  0.0157  0.0039   3.1745   \n",
       "3  1.4882 -0.0124  ...  0.0044   73.8432  0.4990  0.0103  0.0025   2.0544   \n",
       "4  1.5031 -0.0031  ...     NaN       NaN  0.4800  0.4766  0.1045  99.3032   \n",
       "\n",
       "    x_586   x_587   x_588     x_589  \n",
       "0     NaN     NaN     NaN       NaN  \n",
       "1  0.0096  0.0201  0.0060  208.2045  \n",
       "2  0.0584  0.0484  0.0148   82.8602  \n",
       "3  0.0202  0.0149  0.0044   73.8432  \n",
       "4  0.0202  0.0149  0.0044   73.8432  \n",
       "\n",
       "[5 rows x 590 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('data/secom.data', sep=' ', header = None)\n",
    "print('data_df shape = {}'.format(data_df.shape))\n",
    "data_df.columns = ['x_{}'.format(i) for i in range (0,590)]\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1567, 592)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>...</th>\n",
       "      <th>x_582</th>\n",
       "      <th>x_583</th>\n",
       "      <th>x_584</th>\n",
       "      <th>x_585</th>\n",
       "      <th>x_586</th>\n",
       "      <th>x_587</th>\n",
       "      <th>x_588</th>\n",
       "      <th>x_589</th>\n",
       "      <th>Label</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-07-19 12:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-07-19 13:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-07-19 14:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-07-19 15:22:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x_0      x_1        x_2        x_3     x_4    x_5       x_6     x_7  \\\n",
       "0  3030.93  2564.00  2187.7333  1411.1265  1.3602  100.0   97.6133  0.1242   \n",
       "1  3095.78  2465.14  2230.4222  1463.6606  0.8294  100.0  102.3433  0.1247   \n",
       "2  2932.61  2559.94  2186.4111  1698.0172  1.5102  100.0   95.4878  0.1241   \n",
       "3  2988.72  2479.90  2199.0333   909.7926  1.3204  100.0  104.2367  0.1217   \n",
       "4  3032.24  2502.87  2233.3667  1326.5200  1.5334  100.0  100.3967  0.1235   \n",
       "\n",
       "      x_8     x_9  ...   x_582   x_583   x_584    x_585   x_586   x_587  \\\n",
       "0  1.5005  0.0162  ...  0.5005  0.0118  0.0035   2.3630     NaN     NaN   \n",
       "1  1.4966 -0.0005  ...  0.5019  0.0223  0.0055   4.4447  0.0096  0.0201   \n",
       "2  1.4436  0.0041  ...  0.4958  0.0157  0.0039   3.1745  0.0584  0.0484   \n",
       "3  1.4882 -0.0124  ...  0.4990  0.0103  0.0025   2.0544  0.0202  0.0149   \n",
       "4  1.5031 -0.0031  ...  0.4800  0.4766  0.1045  99.3032  0.0202  0.0149   \n",
       "\n",
       "    x_588     x_589  Label                Date  \n",
       "0     NaN       NaN      0 2008-07-19 11:55:00  \n",
       "1  0.0060  208.2045      0 2008-07-19 12:32:00  \n",
       "2  0.0148   82.8602      1 2008-07-19 13:17:00  \n",
       "3  0.0044   73.8432      0 2008-07-19 14:43:00  \n",
       "4  0.0044   73.8432      0 2008-07-19 15:22:00  \n",
       "\n",
       "[5 rows x 592 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = data_df.merge(labels_df, left_index=True, right_index=True)\n",
    "print(merged_df.shape)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy\n",
    "1. Test for univariate correlation and remove those columns with no correlation to label (chi square)\n",
    "3. Feature scaling\n",
    "4. Downsample 100 times and build a model each time.\n",
    "5. Final prediction is ensemble of all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method1: Split Train and Test randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train and Test randomly\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = merged_df.iloc[:,:-2]\n",
    "y = merged_df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(strategy='median').fit(X_train)\n",
    "\n",
    "X_train_imp = pd.DataFrame(imp.transform(X_train))\n",
    "X_train_imp.columns = X_train.columns\n",
    "X_train_imp.index = X_train.index\n",
    "\n",
    "X_test_imp = pd.DataFrame(imp.transform(X_test))\n",
    "X_test_imp.columns = X_test.columns\n",
    "X_test_imp.index = X_test.index\n",
    "\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train_imp)\n",
    "\n",
    "X_train_imp_scaled = pd.DataFrame(scaler.transform(X_train_imp))\n",
    "X_train_imp_scaled.columns = X_train_imp.columns\n",
    "X_train_imp_scaled.index = X_train_imp.index\n",
    "\n",
    "X_test_imp_scaled = pd.DataFrame(scaler.transform(X_test_imp))\n",
    "X_test_imp_scaled.columns = X_test_imp.columns\n",
    "X_test_imp_scaled.index = X_test_imp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi square\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "def feature_prescreen(df_data, X, y):      \n",
    "    data_X = df_data[X]\n",
    "    data_X = data_X.fillna(data_X.median()).fillna(0).as_matrix().astype(float)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    data_X = scaler.fit_transform(data_X)    \n",
    "    data_Y = df_data[y].apply(lambda x: 0 if x==0 else 1).as_matrix() \n",
    "    \n",
    "    # Get top features\n",
    "    feature_selector = SelectKBest(chi2, k='all') \n",
    "    feature_selector.fit(data_X, data_Y)\n",
    "    feature_idx = np.arange(data_X.shape[1])[feature_selector.get_support()].tolist()\n",
    "    features = np.array(X)[feature_idx].tolist()\n",
    "    scores = feature_selector.scores_[feature_idx].tolist()    \n",
    "    pvalues = feature_selector.pvalues_[feature_idx].tolist()    \n",
    "    \n",
    "    feature_prescreen_ranking = pd.DataFrame({'feature': features, 'score': scores, 'pvalue': pvalues})    \n",
    "    feature_prescreen_ranking = feature_prescreen_ranking.sort_values(['score'], ascending=False).reset_index()   \n",
    "    \n",
    "    return feature_prescreen_ranking\n",
    "\n",
    "df_modelling_data = X_train_imp_scaled.merge(y_train, left_index=True, right_index=True)\n",
    "X = df_modelling_data.columns[:-1]\n",
    "y = 'Label'\n",
    "\n",
    "PRESCREEN_CHI_SQUARED_PVALUE = 0.5 #Tuning Parameter\n",
    "\n",
    "feature_prescreen_ranking = feature_prescreen(df_modelling_data, X, y) \n",
    "prescreen_features = feature_prescreen_ranking[feature_prescreen_ranking['pvalue'] < PRESCREEN_CHI_SQUARED_PVALUE]['feature'].tolist()\n",
    "\n",
    "# Split features (X) and response (y)\n",
    "X_train = X_train_imp_scaled[prescreen_features].reset_index(drop=True)\n",
    "X_test = X_test_imp_scaled[prescreen_features].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier train AUC: 0.97\n",
      "Train Precision: 0.83. Train Recall: 0.95. Train FMeasure: 0.88\n",
      "\n",
      "Classifier test AUC: 0.57\n",
      "Test Precision: 0.17. Test Recall: 0.25. Test FMeasure: 0.20\n"
     ]
    }
   ],
   "source": [
    "smt = SMOTE()\n",
    "X_train_sam, y_train_sam = smt.fit_sample(X_train, y_train)\n",
    "\n",
    "clf = GradientBoostingClassifier().fit(X_train_sam, y_train_sam)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "name = 'Classifier'\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_pred_train)\n",
    "precision = metrics.precision_score(y_train, y_pred_train)\n",
    "recall = metrics.recall_score(y_train, y_pred_train)\n",
    "fmeasure = metrics.f1_score(y_train, y_pred_train)\n",
    "print('{} train AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Train Precision: {:0.2f}. Train Recall: {:0.2f}. Train FMeasure: {:0.2f}\\n'.format(precision, recall, fmeasure))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_test)\n",
    "precision = metrics.precision_score(y_test, y_pred_test)\n",
    "recall = metrics.recall_score(y_test, y_pred_test)\n",
    "fmeasure = metrics.f1_score(y_test, y_pred_test)\n",
    "print('{} test AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Test Precision: {:0.2f}. Test Recall: {:0.2f}. Test FMeasure: {:0.2f}'.format(precision, recall, fmeasure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method2: Split Train and Test by Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train df shape: (1208, 592), test df shape: (359, 592)\n"
     ]
    }
   ],
   "source": [
    "# Split Train and Test by date\n",
    "split_date = '2008-10-01'\n",
    "train_df = merged_df[merged_df['Date'] < split_date]\n",
    "test_df = merged_df[merged_df['Date'] >= split_date]\n",
    "print('train df shape: {}, test df shape: {}'.format(train_df.shape, test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi square\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_prescreen(df_data, X, y):      \n",
    "    data_X = df_data[X]\n",
    "    data_X = data_X.fillna(data_X.median()).fillna(0).as_matrix().astype(float)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    data_X = scaler.fit_transform(data_X)    \n",
    "    data_Y = df_data[y].apply(lambda x: 0 if x==0 else 1).as_matrix() \n",
    "    \n",
    "    # Get top features\n",
    "    feature_selector = SelectKBest(chi2, k='all') \n",
    "    feature_selector.fit(data_X, data_Y)\n",
    "    feature_idx = np.arange(data_X.shape[1])[feature_selector.get_support()].tolist()\n",
    "    features = np.array(X)[feature_idx].tolist()\n",
    "    scores = feature_selector.scores_[feature_idx].tolist()    \n",
    "    pvalues = feature_selector.pvalues_[feature_idx].tolist()    \n",
    "    \n",
    "    feature_prescreen_ranking = pd.DataFrame({'feature': features, 'score': scores, 'pvalue': pvalues})    \n",
    "    feature_prescreen_ranking = feature_prescreen_ranking.sort_values(['score'], ascending=False).reset_index()   \n",
    "    \n",
    "    return feature_prescreen_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelling_data = train_df\n",
    "X = train_df.columns[:-2]\n",
    "y = 'Label'\n",
    "PRESCREEN_CHI_SQUARED_PVALUE = 0.5 #Tuning Parameter\n",
    "\n",
    "feature_prescreen_ranking = feature_prescreen(df_modelling_data, X, y) \n",
    "prescreen_features = feature_prescreen_ranking[feature_prescreen_ranking['pvalue'] < PRESCREEN_CHI_SQUARED_PVALUE]['feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features (X) and response (y)\n",
    "X_train = train_df[prescreen_features].reset_index(drop=True)\n",
    "y_train = train_df['Label'].reset_index(drop=True)\n",
    "X_test = test_df[prescreen_features].reset_index(drop=True)\n",
    "y_test = test_df['Label'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(strategy='median')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "X_train_imp = imp.transform(X_train)\n",
    "X_test_imp = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = MinMaxScaler().fit(X_train_imp)\n",
    "X_train_imp_scaled = scaler.transform(X_train_imp)\n",
    "X_test_imp_scaled = scaler.transform(X_test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msleo\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n",
      "C:\\Users\\msleo\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Outlier detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Train the model on training dataset with label == 0\n",
    "clf = IsolationForest(random_state=1)\n",
    "clf.fit(X_train_imp_scaled[y_train[y_train == 0].index])\n",
    "\n",
    "# predictions\n",
    "train_outliers = clf.predict(X_train_imp_scaled)\n",
    "test_outliers = clf.predict(X_test_imp_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add outlier prediction as a feature column\n",
    "X_train_imp_scaled_append = np.column_stack((X_train_imp_scaled, train_outliers))\n",
    "X_test_imp_scaled_append = np.column_stack((X_test_imp_scaled, test_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier train AUC: 0.93\n",
      "Train Precision: 0.65. Train Recall: 0.89. Train FMeasure: 0.75\n",
      "\n",
      "Classifier test AUC: 0.49\n",
      "Test Precision: 0.00. Test Recall: 0.00. Test FMeasure: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Single Gradient Boosting\n",
    "ros = RandomOverSampler(sampling_strategy = 0.5)\n",
    "smt = SMOTE()\n",
    "X_train_sam, y_train_sam = smt.fit_sample(X_train_imp_scaled_append, y_train)\n",
    "\n",
    "clf = GradientBoostingClassifier().fit(X_train_sam, y_train_sam)\n",
    "y_pred_train = clf.predict(X_train_imp_scaled_append)\n",
    "y_pred_test = clf.predict(X_test_imp_scaled_append)\n",
    "\n",
    "from sklearn import metrics\n",
    "name = 'Classifier'\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_pred_train)\n",
    "precision = metrics.precision_score(y_train, y_pred_train)\n",
    "recall = metrics.recall_score(y_train, y_pred_train)\n",
    "fmeasure = metrics.f1_score(y_train, y_pred_train)\n",
    "print('{} train AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Train Precision: {:0.2f}. Train Recall: {:0.2f}. Train FMeasure: {:0.2f}\\n'.format(precision, recall, fmeasure))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_test)\n",
    "precision = metrics.precision_score(y_test, y_pred_test)\n",
    "recall = metrics.recall_score(y_test, y_pred_test)\n",
    "fmeasure = metrics.f1_score(y_test, y_pred_test)\n",
    "print('{} test AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Test Precision: {:0.2f}. Test Recall: {:0.2f}. Test FMeasure: {:0.2f}'.format(precision, recall, fmeasure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method3: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:   21.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 536 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:   22.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:   20.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 685 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:   23.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 536 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:   23.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [2, 5, 10],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [10, 20, 30]\n",
    "}\n",
    "n = 5\n",
    "clf_list = []\n",
    "for i in range(n):\n",
    "    ros = RandomOverSampler(random_state=i)\n",
    "    #smt = SMOTE()\n",
    "    #X_train_sam, y_train_sam = smt.fit_sample(X_train_imp_scaled_append, y_train)\n",
    "    X_train_sam, y_train_sam = ros.fit_sample(X_train_imp_scaled_append, y_train)\n",
    "    \n",
    "    clf = GradientBoostingClassifier(random_state=i)\n",
    "    grid_search = GridSearchCV(estimator = clf, param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 2, iid=True)  \n",
    "    clf_list.append(grid_search.fit(X_train_sam, y_train_sam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'max_depth': 10, 'max_features': 2, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 30}\n",
      "\n",
      "best params: {'max_depth': 10, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 20}\n",
      "\n",
      "best params: {'max_depth': 10, 'max_features': 2, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 30}\n",
      "\n",
      "best params: {'max_depth': 10, 'max_features': 2, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 30}\n",
      "\n",
      "best params: {'max_depth': 10, 'max_features': 2, 'min_samples_leaf': 3, 'min_samples_split': 12, 'n_estimators': 20}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_list = []\n",
    "y_pred_test_list = []\n",
    "for clf in clf_list:\n",
    "    print('best params: {}\\n'.format(clf.best_params_))\n",
    "    y_pred_train = clf.predict(X_train_imp_scaled_append)\n",
    "    y_pred_train_list.append(y_pred_train)\n",
    "    \n",
    "    y_pred_test = clf.predict(X_test_imp_scaled_append)\n",
    "    y_pred_test_list.append(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = np.array(y_pred_train_list)\n",
    "y_pred_train_ = np.mean(y_pred_list, axis=0)\n",
    "y_pred_train = [0 if x < 0.15 else 1 for x in y_pred_train_]\n",
    "\n",
    "y_pred_list = np.array(y_pred_test_list)\n",
    "y_pred_test_ = np.mean(y_pred_list, axis=0)\n",
    "y_pred_test = [0 if x < 0.15 else 1 for x in y_pred_test_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled Classifier train AUC: 1.00\n",
      "Train Precision: 1.00. Train Recall: 1.00\n",
      "\n",
      "Downsampled Classifier test AUC: 0.50\n",
      "Test Precision: 0.00. Test Recall: 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "name = 'Downsampled Classifier'\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_pred_train)\n",
    "precision = metrics.precision_score(y_train, y_pred_train)\n",
    "recall = metrics.recall_score(y_train, y_pred_train)\n",
    "print('{} train AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Train Precision: {:0.2f}. Train Recall: {:0.2f}\\n'.format(precision, recall))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_test)\n",
    "precision = metrics.precision_score(y_test, y_pred_test)\n",
    "recall = metrics.recall_score(y_test, y_pred_test)\n",
    "print('{} test AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Test Precision: {:0.2f}. Test Recall: {:0.2f}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "1. No good model could be found on the test data\n",
    "2. All models are seriously overfitting\n",
    "2. Need to find a way to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other random methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data univariate correlation\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_pvalues = []\n",
    "for col in train_df.columns[:-2]:\n",
    "    df_clean = train_df[[col, 'Label']].dropna()\n",
    "    pearson_corr, pearson_pvalue = pearsonr(df_clean[col], df_clean['Label'])\n",
    "    pearson_pvalues.append(pearson_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_colidx = [i for i, n in enumerate(pearson_pvalues) if n <= 0.05]\n",
    "sig_colidx.extend([-2, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_red_dim = train_df.iloc[:, sig_colidx]\n",
    "test_df_red_dim = test_df.iloc[:, sig_colidx]\n",
    "print('train df shape: {}, test df shape: {}'.format(train_df_red_dim.shape, test_df_red_dim.shape))\n",
    "train_df_red_dim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features (X) and response (y)\n",
    "X_train = train_df_red_dim.iloc[:,:-2].reset_index(drop=True)\n",
    "y_train = train_df_red_dim.iloc[:,-2].reset_index(drop=True)\n",
    "X_test = test_df_red_dim.iloc[:,:-2].reset_index(drop=True)\n",
    "y_test = test_df_red_dim.iloc[:,-2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_missing_count = data_df.isna().sum()\n",
    "data_df_missing_count[data_df_missing_count > 100].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data_df, labels_df, split_date):\n",
    "    y_train = labels_df['Label'][labels_df['Date'] < split_date]\n",
    "    y_test = labels_df['Label'][labels_df['Date'] >= split_date]\n",
    "    \n",
    "    X_train = data_df.loc[y_train.index]\n",
    "    X_test = data_df.loc[y_test.index]\n",
    "    \n",
    "    print('X_train, y_train, X_test, y_test shapes: {}, {}, {}, {}'\\\n",
    "      .format(X_train.shape, y_train.shape, X_test.shape, y_test.shape))\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(data_df, labels_df, '2008-10-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_comparison(X_train, y_train, X_test, y_test):\n",
    "    names = [\"Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\", \"Gradient Boosting\", \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "    classifiers = [\n",
    "        KNeighborsClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        MLPClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        GaussianNB(),\n",
    "        QuadraticDiscriminantAnalysis()]\n",
    "    \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_train)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_train, y_pred)\n",
    "        print('{} train AUC: {}'.format(name, metrics.auc(fpr, tpr)))\n",
    "        y_pred = clf.predict(X_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "        print('{} test AUC: {}\\n'.format(name, metrics.auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "X_train_imp = imp.transform(X_train)\n",
    "X_test_imp = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifier_comparison(X_train_imp, y_train, X_test_imp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smt = SMOTE()\n",
    "X_train_imp_smt, y_train_smt = smt.fit_sample(X_train_imp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.hist(y_train)\n",
    "plt.title('y_train')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y_train_smt)\n",
    "plt.title('y_train_smt')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_comparison(X_train_imp_smt, y_train_smt, X_test_imp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.97)\n",
    "pca.fit(X_train_imp)  \n",
    "\n",
    "print(pca.explained_variance_ratio_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp_pca = pca.transform(X_train_imp)\n",
    "X_test_imp_pca = pca.transform(X_test_imp)\n",
    "classifier_comparison(X_train_imp_pca, y_train, X_test_imp_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "ros = RandomUnderSampler(random_state=1)\n",
    "X_train_imp_pca_sam, y_train_sam = ros.fit_sample(X_train_imp_pca, y_train)\n",
    "plt.hist(y_train_sam);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_comparison(X_train_imp_pca_sam, y_train_sam, X_test_imp_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "\n",
    "#classifier_comparison(X_train_imp_pca, y_train, X_test_imp_pca, y_test)\n",
    "clf = IsolationForest(random_state=1, bootstrap = True, max_features =0.6)\n",
    "clf.fit(X_train_imp)\n",
    "\n",
    "# predictions\n",
    "y_pred_train = clf.predict(X_train_imp)\n",
    "y_pred_test = clf.predict(X_test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = [1 if x < 0 else 0 for x in y_pred_train]\n",
    "y_pred_test = [1 if x < 0 else 0 for x in y_pred_test]\n",
    "\n",
    "name = 'Isolation Forest'\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_pred_train)\n",
    "precision = precision_score(y_train, y_pred_train)\n",
    "recall = recall_score(y_train, y_pred_train)\n",
    "print('{} train AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Train Precision: {:0.2f}. Train Recall: {:0.2f}\\n'.format(precision, recall))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test)\n",
    "recall = recall_score(y_test, y_pred_test)\n",
    "print('{} test AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Test Precision: {:0.2f}. Test Recall: {:0.2f}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_smt = PCA(n_components=0.97)\n",
    "pca_smt.fit(X_train_imp_smt)  \n",
    "\n",
    "print(pca_smt.explained_variance_ratio_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp_smt_pca = pca_smt.transform(X_train_imp_smt)\n",
    "X_test_imp_pca = pca_smt.transform(X_test_imp)\n",
    "classifier_comparison(X_train_imp_smt_pca, y_train_smt, X_test_imp_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Random Forest'\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_imp_sam, y_train_sam)\n",
    "y_pred = clf.predict(X_train_imp_sam)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train_sam, y_pred)\n",
    "precision = precision_score(y_train_sam, y_pred)\n",
    "recall = recall_score(y_train_sam, y_pred)\n",
    "print('{} train AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Train Precision: {:0.2f}. Train Recall: {:0.2f}\\n'.format(precision, recall))\n",
    "\n",
    "y_pred = clf.predict(X_test_imp)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('{} test AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Test Precision: {:0.2f}. Train Recall: {:0.2f}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Classifier'\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "clf = BalancedRandomForestClassifier(max_depth=2, random_state=0, max_features=0.6)\n",
    "\n",
    "clf.fit(X_train_imp, y_train)\n",
    "y_pred = clf.predict(X_train_imp)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_pred)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('{} train AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Train Precision: {:0.2f}. Train Recall: {:0.2f}\\n'.format(precision, recall))\n",
    "\n",
    "y_pred = clf.predict(X_test_imp)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('{} test AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Test Precision: {:0.2f}. Train Recall: {:0.2f}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
