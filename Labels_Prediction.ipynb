{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_df shape = (1567, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 12:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-07-19 13:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 14:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 15:22:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                Date\n",
       "0     -1 2008-07-19 11:55:00\n",
       "1     -1 2008-07-19 12:32:00\n",
       "2      1 2008-07-19 13:17:00\n",
       "3     -1 2008-07-19 14:43:00\n",
       "4     -1 2008-07-19 15:22:00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv('data/secom_labels.data', sep=' ', header = None)\n",
    "labels_df.columns = ['Label', 'Date']\n",
    "labels_df['Date'] = pd.to_datetime(labels_df['Date'], format = \"%d/%m/%Y %H:%M:%S\")\n",
    "print('labels_df shape = {}'.format(labels_df.shape))\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fbc7ec5fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_df['Label'] = labels_df['Label'].apply(lambda x: 0 if x == -1 else 1)\n",
    "labels_df['Label'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-07-19</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-07-20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-07-21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-07-22</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-07-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Sum  Count\n",
       "0 2008-07-19    3     12\n",
       "1 2008-07-20    0      1\n",
       "2 2008-07-21    1      2\n",
       "3 2008-07-22    0      6\n",
       "4 2008-07-23    0      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_sum = labels_df['Label'].groupby(labels_df['Date'].dt.date).sum().reset_index()\n",
    "label_count = labels_df['Label'].groupby(labels_df['Date'].dt.date).count().reset_index()\n",
    "label_day = pd.merge(label_sum, label_count, on='Date')\n",
    "label_day.columns = ['Date', 'Sum', 'Count']\n",
    "label_day['Date'] = pd.to_datetime(label_day['Date'])\n",
    "label_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure with shared X axis\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, figsize = (15,7))\n",
    "\n",
    "# Remove horizontal space between axes\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "# Set the width of the bars to be 1 day\n",
    "#width = np.timedelta64(1, 'D')\n",
    "\n",
    "# Plot the Sum of fails per day and count of entries per day\n",
    "axs[0].bar(label_day['Date'], label_day['Sum'], color = 'red')\n",
    "axs[1].bar(label_day['Date'], label_day['Count'], color = 'blue')\n",
    "axs[0].set_ylabel('Total Fails per day')\n",
    "axs[1].set_ylabel('Total Count of data per day')\n",
    "axs[1].set_xlabel('Date');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_df shape = (1567, 590)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>...</th>\n",
       "      <th>x_580</th>\n",
       "      <th>x_581</th>\n",
       "      <th>x_582</th>\n",
       "      <th>x_583</th>\n",
       "      <th>x_584</th>\n",
       "      <th>x_585</th>\n",
       "      <th>x_586</th>\n",
       "      <th>x_587</th>\n",
       "      <th>x_588</th>\n",
       "      <th>x_589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x_0      x_1        x_2        x_3     x_4    x_5       x_6     x_7  \\\n",
       "0  3030.93  2564.00  2187.7333  1411.1265  1.3602  100.0   97.6133  0.1242   \n",
       "1  3095.78  2465.14  2230.4222  1463.6606  0.8294  100.0  102.3433  0.1247   \n",
       "2  2932.61  2559.94  2186.4111  1698.0172  1.5102  100.0   95.4878  0.1241   \n",
       "3  2988.72  2479.90  2199.0333   909.7926  1.3204  100.0  104.2367  0.1217   \n",
       "4  3032.24  2502.87  2233.3667  1326.5200  1.5334  100.0  100.3967  0.1235   \n",
       "\n",
       "      x_8     x_9  ...   x_580     x_581   x_582   x_583   x_584    x_585  \\\n",
       "0  1.5005  0.0162  ...     NaN       NaN  0.5005  0.0118  0.0035   2.3630   \n",
       "1  1.4966 -0.0005  ...  0.0060  208.2045  0.5019  0.0223  0.0055   4.4447   \n",
       "2  1.4436  0.0041  ...  0.0148   82.8602  0.4958  0.0157  0.0039   3.1745   \n",
       "3  1.4882 -0.0124  ...  0.0044   73.8432  0.4990  0.0103  0.0025   2.0544   \n",
       "4  1.5031 -0.0031  ...     NaN       NaN  0.4800  0.4766  0.1045  99.3032   \n",
       "\n",
       "    x_586   x_587   x_588     x_589  \n",
       "0     NaN     NaN     NaN       NaN  \n",
       "1  0.0096  0.0201  0.0060  208.2045  \n",
       "2  0.0584  0.0484  0.0148   82.8602  \n",
       "3  0.0202  0.0149  0.0044   73.8432  \n",
       "4  0.0202  0.0149  0.0044   73.8432  \n",
       "\n",
       "[5 rows x 590 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('data/secom.data', sep=' ', header = None)\n",
    "print('data_df shape = {}'.format(data_df.shape))\n",
    "data_df.columns = ['x_{}'.format(i) for i in range (0,590)]\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1567, 592)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>...</th>\n",
       "      <th>x_582</th>\n",
       "      <th>x_583</th>\n",
       "      <th>x_584</th>\n",
       "      <th>x_585</th>\n",
       "      <th>x_586</th>\n",
       "      <th>x_587</th>\n",
       "      <th>x_588</th>\n",
       "      <th>x_589</th>\n",
       "      <th>Label</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-07-19 12:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-07-19 13:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-07-19 14:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-07-19 15:22:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x_0      x_1        x_2        x_3     x_4    x_5       x_6     x_7  \\\n",
       "0  3030.93  2564.00  2187.7333  1411.1265  1.3602  100.0   97.6133  0.1242   \n",
       "1  3095.78  2465.14  2230.4222  1463.6606  0.8294  100.0  102.3433  0.1247   \n",
       "2  2932.61  2559.94  2186.4111  1698.0172  1.5102  100.0   95.4878  0.1241   \n",
       "3  2988.72  2479.90  2199.0333   909.7926  1.3204  100.0  104.2367  0.1217   \n",
       "4  3032.24  2502.87  2233.3667  1326.5200  1.5334  100.0  100.3967  0.1235   \n",
       "\n",
       "      x_8     x_9  ...   x_582   x_583   x_584    x_585   x_586   x_587  \\\n",
       "0  1.5005  0.0162  ...  0.5005  0.0118  0.0035   2.3630     NaN     NaN   \n",
       "1  1.4966 -0.0005  ...  0.5019  0.0223  0.0055   4.4447  0.0096  0.0201   \n",
       "2  1.4436  0.0041  ...  0.4958  0.0157  0.0039   3.1745  0.0584  0.0484   \n",
       "3  1.4882 -0.0124  ...  0.4990  0.0103  0.0025   2.0544  0.0202  0.0149   \n",
       "4  1.5031 -0.0031  ...  0.4800  0.4766  0.1045  99.3032  0.0202  0.0149   \n",
       "\n",
       "    x_588     x_589  Label                Date  \n",
       "0     NaN       NaN      0 2008-07-19 11:55:00  \n",
       "1  0.0060  208.2045      0 2008-07-19 12:32:00  \n",
       "2  0.0148   82.8602      1 2008-07-19 13:17:00  \n",
       "3  0.0044   73.8432      0 2008-07-19 14:43:00  \n",
       "4  0.0044   73.8432      0 2008-07-19 15:22:00  \n",
       "\n",
       "[5 rows x 592 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = data_df.merge(labels_df, left_index=True, right_index=True)\n",
    "print(merged_df.shape)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train and Test based on date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train df shape: (1208, 592), test df shape: (359, 592)\n"
     ]
    }
   ],
   "source": [
    "split_date = '2008-10-01'\n",
    "train_df = merged_df[merged_df['Date'] < split_date]\n",
    "test_df = merged_df[merged_df['Date'] >= split_date]\n",
    "print('train df shape: {}, test df shape: {}'.format(train_df.shape, test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy\n",
    "1. Test for univariate correlation and remove those columns with no correlation to label (chi square)\n",
    "2. Find outliers using Isolation forest and add as a new feature\n",
    "3. Feature scaling\n",
    "4. Downsample 100 times and build a model each time.\n",
    "5. Final prediction is ensemble of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data univariate correlation\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_pvalues = []\n",
    "for col in train_df.columns[:-2]:\n",
    "    df_clean = train_df[[col, 'Label']].dropna()\n",
    "    pearson_corr, pearson_pvalue = pearsonr(df_clean[col], df_clean['Label'])\n",
    "    pearson_pvalues.append(pearson_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_colidx = [i for i, n in enumerate(pearson_pvalues) if n <= 0.05]\n",
    "sig_colidx.extend([-2, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train df shape: (1208, 83), test df shape: (359, 83)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_21</th>\n",
       "      <th>x_22</th>\n",
       "      <th>x_26</th>\n",
       "      <th>x_28</th>\n",
       "      <th>x_30</th>\n",
       "      <th>x_33</th>\n",
       "      <th>x_59</th>\n",
       "      <th>x_63</th>\n",
       "      <th>...</th>\n",
       "      <th>x_551</th>\n",
       "      <th>x_553</th>\n",
       "      <th>x_554</th>\n",
       "      <th>x_556</th>\n",
       "      <th>x_557</th>\n",
       "      <th>x_562</th>\n",
       "      <th>x_587</th>\n",
       "      <th>x_588</th>\n",
       "      <th>Label</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>7.9558</td>\n",
       "      <td>-5419.00</td>\n",
       "      <td>2916.50</td>\n",
       "      <td>1.7730</td>\n",
       "      <td>64.2333</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>9.5126</td>\n",
       "      <td>-1.7264</td>\n",
       "      <td>16.1445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>5.7349</td>\n",
       "      <td>0.3363</td>\n",
       "      <td>3.2687</td>\n",
       "      <td>1.0297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>10.1548</td>\n",
       "      <td>-5441.50</td>\n",
       "      <td>2604.25</td>\n",
       "      <td>2.0143</td>\n",
       "      <td>68.4222</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>9.7997</td>\n",
       "      <td>0.8073</td>\n",
       "      <td>10.9036</td>\n",
       "      <td>...</td>\n",
       "      <td>1.33</td>\n",
       "      <td>7.1196</td>\n",
       "      <td>0.4989</td>\n",
       "      <td>3.9139</td>\n",
       "      <td>1.7819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-07-19 12:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>9.5157</td>\n",
       "      <td>-5447.75</td>\n",
       "      <td>2701.75</td>\n",
       "      <td>2.0295</td>\n",
       "      <td>67.1333</td>\n",
       "      <td>0.1734</td>\n",
       "      <td>8.6590</td>\n",
       "      <td>23.8245</td>\n",
       "      <td>11.3019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>7.1619</td>\n",
       "      <td>0.3752</td>\n",
       "      <td>3.9306</td>\n",
       "      <td>1.1386</td>\n",
       "      <td>267.064</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-07-19 13:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>9.6052</td>\n",
       "      <td>-5468.25</td>\n",
       "      <td>2648.25</td>\n",
       "      <td>2.0038</td>\n",
       "      <td>62.9333</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>8.6789</td>\n",
       "      <td>24.3791</td>\n",
       "      <td>13.5597</td>\n",
       "      <td>...</td>\n",
       "      <td>39.33</td>\n",
       "      <td>56.9303</td>\n",
       "      <td>17.4781</td>\n",
       "      <td>35.3198</td>\n",
       "      <td>54.2917</td>\n",
       "      <td>268.228</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-07-19 14:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>10.5661</td>\n",
       "      <td>-5476.25</td>\n",
       "      <td>2635.25</td>\n",
       "      <td>1.9912</td>\n",
       "      <td>62.8333</td>\n",
       "      <td>0.2696</td>\n",
       "      <td>8.7677</td>\n",
       "      <td>-12.2945</td>\n",
       "      <td>21.9782</td>\n",
       "      <td>...</td>\n",
       "      <td>1.98</td>\n",
       "      <td>9.7608</td>\n",
       "      <td>0.8311</td>\n",
       "      <td>4.9086</td>\n",
       "      <td>2.5014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-07-19 15:22:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x_0     x_14     x_21     x_22    x_26     x_28    x_30    x_33  \\\n",
       "0  3030.93   7.9558 -5419.00  2916.50  1.7730  64.2333  0.1632  9.5126   \n",
       "1  3095.78  10.1548 -5441.50  2604.25  2.0143  68.4222  0.2102  9.7997   \n",
       "2  2932.61   9.5157 -5447.75  2701.75  2.0295  67.1333  0.1734  8.6590   \n",
       "3  2988.72   9.6052 -5468.25  2648.25  2.0038  62.9333  0.2071  8.6789   \n",
       "4  3032.24  10.5661 -5476.25  2635.25  1.9912  62.8333  0.2696  8.7677   \n",
       "\n",
       "      x_59     x_63  ...  x_551    x_553    x_554    x_556    x_557    x_562  \\\n",
       "0  -1.7264  16.1445  ...   0.78   5.7349   0.3363   3.2687   1.0297      NaN   \n",
       "1   0.8073  10.9036  ...   1.33   7.1196   0.4989   3.9139   1.7819      NaN   \n",
       "2  23.8245  11.3019  ...   0.85   7.1619   0.3752   3.9306   1.1386  267.064   \n",
       "3  24.3791  13.5597  ...  39.33  56.9303  17.4781  35.3198  54.2917  268.228   \n",
       "4 -12.2945  21.9782  ...   1.98   9.7608   0.8311   4.9086   2.5014      NaN   \n",
       "\n",
       "    x_587   x_588  Label                Date  \n",
       "0     NaN     NaN      0 2008-07-19 11:55:00  \n",
       "1  0.0201  0.0060      0 2008-07-19 12:32:00  \n",
       "2  0.0484  0.0148      1 2008-07-19 13:17:00  \n",
       "3  0.0149  0.0044      0 2008-07-19 14:43:00  \n",
       "4  0.0149  0.0044      0 2008-07-19 15:22:00  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_red_dim = train_df.iloc[:, sig_colidx]\n",
    "test_df_red_dim = test_df.iloc[:, sig_colidx]\n",
    "print('train df shape: {}, test df shape: {}'.format(train_df_red_dim.shape, test_df_red_dim.shape))\n",
    "train_df_red_dim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features (X) and response (y)\n",
    "X_train = train_df_red_dim.iloc[:,:-2].reset_index(drop=True)\n",
    "y_train = train_df_red_dim.iloc[:,-2].reset_index(drop=True)\n",
    "X_test = test_df_red_dim.iloc[:,:-2].reset_index(drop=True)\n",
    "y_test = test_df_red_dim.iloc[:,-2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "X_train_imp = imp.transform(X_train)\n",
    "X_test_imp = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Outlier detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Train the model on training dataset with label == 0\n",
    "clf = IsolationForest(random_state=1)\n",
    "clf.fit(X_train_imp[y_train[y_train == 0].index])\n",
    "\n",
    "# predictions\n",
    "train_outliers = clf.predict(X_train_imp)\n",
    "test_outliers = clf.predict(X_test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add outlier prediction as a feature column\n",
    "X_train_imp_append = np.column_stack((X_train_imp, train_outliers))\n",
    "X_test_imp_append = np.column_stack((X_test_imp, test_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_non_outliers_idx = [i for i, n in enumerate(train_outliers) if n > 0]\n",
    "# test_non_outliers_idx = [i for i, n in enumerate(test_outliers) if n > 0]\n",
    "# X_train_out = X_train_imp[train_non_outliers_idx]\n",
    "# y_train_out = y_train[train_non_outliers_idx]\n",
    "# X_test_out = X_train_imp[test_non_outliers_idx]\n",
    "# y_test_out = y_test[test_non_outliers_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Downsample 100 times\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:    6.2s finished\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 608 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:    4.3s finished\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 558 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:    4.2s finished\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 608 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:    4.1s finished\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:    3.9s finished\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [2, 5, 10],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [10, 20, 30]\n",
    "}\n",
    "n = 5\n",
    "clf_list = []\n",
    "for i in range(n):\n",
    "    ros = RandomUnderSampler(random_state=i)\n",
    "    X_train_sam, y_train_sam = ros.fit_sample(X_train_imp_append, y_train)\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=i)\n",
    "    grid_search = GridSearchCV(estimator = clf, param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 2)  \n",
    "    clf_list.append(grid_search.fit(X_train_sam, y_train_sam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'bootstrap': True, 'max_depth': 5, 'max_features': 2, 'min_samples_leaf': 5, 'min_samples_split': 8, 'n_estimators': 20}\n",
      "\n",
      "best params: {'bootstrap': True, 'max_depth': 5, 'max_features': 3, 'min_samples_leaf': 5, 'min_samples_split': 8, 'n_estimators': 10}\n",
      "\n",
      "best params: {'bootstrap': True, 'max_depth': 10, 'max_features': 2, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 30}\n",
      "\n",
      "best params: {'bootstrap': True, 'max_depth': 10, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 20}\n",
      "\n",
      "best params: {'bootstrap': True, 'max_depth': 5, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 20}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_list = []\n",
    "y_pred_test_list = []\n",
    "for clf in clf_list:\n",
    "    print('best params: {}\\n'.format(clf.best_params_))\n",
    "    y_pred_train = clf.predict(X_train_imp_append)\n",
    "    y_pred_train_list.append(y_pred_train)\n",
    "    \n",
    "    y_pred_test = clf.predict(X_test_imp_append)\n",
    "    y_pred_test_list.append(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = np.array(y_pred_train_list)\n",
    "y_pred_train_ = np.mean(y_pred_list, axis=0)\n",
    "y_pred_train = [0 if x < 0.5 else 1 for x in y_pred_train_]\n",
    "\n",
    "y_pred_list = np.array(y_pred_test_list)\n",
    "y_pred_test_ = np.mean(y_pred_list, axis=0)\n",
    "y_pred_test = [0 if x < 0.5 else 1 for x in y_pred_test_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled Classifier train AUC: 0.87\n",
      "Train Precision: 0.22. Train Recall: 0.99\n",
      "\n",
      "Downsampled Classifier test AUC: 0.54\n",
      "Test Precision: 0.10. Test Recall: 0.18\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "name = 'Downsampled Classifier'\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_pred_train)\n",
    "precision = metrics.precision_score(y_train, y_pred_train)\n",
    "recall = metrics.recall_score(y_train, y_pred_train)\n",
    "print('{} train AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Train Precision: {:0.2f}. Train Recall: {:0.2f}\\n'.format(precision, recall))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_test)\n",
    "precision = metrics.precision_score(y_test, y_pred_test)\n",
    "recall = metrics.recall_score(y_test, y_pred_test)\n",
    "print('{} test AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Test Precision: {:0.2f}. Test Recall: {:0.2f}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[300,  37],\n",
       "       [ 18,   4]], dtype=int64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([135.,   0., 124.,   0.,  59.,  27.,   0.,   0.,  12.,   2.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_missing_count = data_df.isna().sum()\n",
    "data_df_missing_count[data_df_missing_count > 100].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data_df, labels_df, split_date):\n",
    "    y_train = labels_df['Label'][labels_df['Date'] < split_date]\n",
    "    y_test = labels_df['Label'][labels_df['Date'] >= split_date]\n",
    "    \n",
    "    X_train = data_df.loc[y_train.index]\n",
    "    X_test = data_df.loc[y_test.index]\n",
    "    \n",
    "    print('X_train, y_train, X_test, y_test shapes: {}, {}, {}, {}'\\\n",
    "      .format(X_train.shape, y_train.shape, X_test.shape, y_test.shape))\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(data_df, labels_df, '2008-10-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_comparison(X_train, y_train, X_test, y_test):\n",
    "    names = [\"Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\", \"Gradient Boosting\", \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "    classifiers = [\n",
    "        KNeighborsClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        MLPClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        GaussianNB(),\n",
    "        QuadraticDiscriminantAnalysis()]\n",
    "    \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_train)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_train, y_pred)\n",
    "        print('{} train AUC: {}'.format(name, metrics.auc(fpr, tpr)))\n",
    "        y_pred = clf.predict(X_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "        print('{} test AUC: {}\\n'.format(name, metrics.auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "X_train_imp = imp.transform(X_train)\n",
    "X_test_imp = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifier_comparison(X_train_imp, y_train, X_test_imp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smt = SMOTE()\n",
    "X_train_imp_smt, y_train_smt = smt.fit_sample(X_train_imp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.hist(y_train)\n",
    "plt.title('y_train')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y_train_smt)\n",
    "plt.title('y_train_smt')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_comparison(X_train_imp_smt, y_train_smt, X_test_imp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.97)\n",
    "pca.fit(X_train_imp)  \n",
    "\n",
    "print(pca.explained_variance_ratio_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp_pca = pca.transform(X_train_imp)\n",
    "X_test_imp_pca = pca.transform(X_test_imp)\n",
    "classifier_comparison(X_train_imp_pca, y_train, X_test_imp_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "ros = RandomUnderSampler(random_state=1)\n",
    "X_train_imp_pca_sam, y_train_sam = ros.fit_sample(X_train_imp_pca, y_train)\n",
    "plt.hist(y_train_sam);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_comparison(X_train_imp_pca_sam, y_train_sam, X_test_imp_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "\n",
    "#classifier_comparison(X_train_imp_pca, y_train, X_test_imp_pca, y_test)\n",
    "clf = IsolationForest(random_state=1, bootstrap = True, max_features =0.6)\n",
    "clf.fit(X_train_imp)\n",
    "\n",
    "# predictions\n",
    "y_pred_train = clf.predict(X_train_imp)\n",
    "y_pred_test = clf.predict(X_test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = [1 if x < 0 else 0 for x in y_pred_train]\n",
    "y_pred_test = [1 if x < 0 else 0 for x in y_pred_test]\n",
    "\n",
    "name = 'Isolation Forest'\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_pred_train)\n",
    "precision = precision_score(y_train, y_pred_train)\n",
    "recall = recall_score(y_train, y_pred_train)\n",
    "print('{} train AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Train Precision: {:0.2f}. Train Recall: {:0.2f}\\n'.format(precision, recall))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test)\n",
    "recall = recall_score(y_test, y_pred_test)\n",
    "print('{} test AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Test Precision: {:0.2f}. Test Recall: {:0.2f}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_smt = PCA(n_components=0.97)\n",
    "pca_smt.fit(X_train_imp_smt)  \n",
    "\n",
    "print(pca_smt.explained_variance_ratio_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp_smt_pca = pca_smt.transform(X_train_imp_smt)\n",
    "X_test_imp_pca = pca_smt.transform(X_test_imp)\n",
    "classifier_comparison(X_train_imp_smt_pca, y_train_smt, X_test_imp_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Random Forest'\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_imp_sam, y_train_sam)\n",
    "y_pred = clf.predict(X_train_imp_sam)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train_sam, y_pred)\n",
    "precision = precision_score(y_train_sam, y_pred)\n",
    "recall = recall_score(y_train_sam, y_pred)\n",
    "print('{} train AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Train Precision: {:0.2f}. Train Recall: {:0.2f}\\n'.format(precision, recall))\n",
    "\n",
    "y_pred = clf.predict(X_test_imp)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('{} test AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Test Precision: {:0.2f}. Train Recall: {:0.2f}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Classifier'\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "clf = BalancedRandomForestClassifier(max_depth=2, random_state=0, max_features=0.6)\n",
    "\n",
    "clf.fit(X_train_imp, y_train)\n",
    "y_pred = clf.predict(X_train_imp)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_pred)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('{} train AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Train Precision: {:0.2f}. Train Recall: {:0.2f}\\n'.format(precision, recall))\n",
    "\n",
    "y_pred = clf.predict(X_test_imp)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('{} test AUC: {:0.2f}'.format(name, metrics.auc(fpr, tpr)))\n",
    "print('Test Precision: {:0.2f}. Train Recall: {:0.2f}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where –1 corresponds to a pass and 1 corresponds to a fail and the data time stamp is for that specific test point.\n",
    "data = pd.read_csv(\"data/secom.data\",  delimiter=' ', header=None, index_col=False)\n",
    "target = pd.read_csv(\"data/secom_labels.data\", header=None, index_col=False, delimiter=' ', usecols=[0])\n",
    "data_size, feature_size = data.shape\n",
    "\n",
    "'''pre processing steps'''\n",
    "\n",
    "data = data.dropna(axis=1, thresh=int(2*data_size/4))\n",
    "data_size, feature_size = data.shape\n",
    "data = data.dropna(axis=0, thresh=int(2*feature_size/4))\n",
    "imputer = preprocessing.Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "target = np.asarray(target).reshape((data_size,))\n",
    "data = np.asarray(data)\n",
    "low_Var = VarianceThreshold(0.1)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "pca = PCA(n_components=10,svd_solver='full')\n",
    "\n",
    "''' customized accuracy scores '''\n",
    "\n",
    "\n",
    "def tp_rate(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]/(confusion_matrix(y_true, y_pred)[0, 0] +\n",
    "                                                                            confusion_matrix(y_true, y_pred)[0, 1])\n",
    "\n",
    "\n",
    "def tn_rate(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]/(confusion_matrix(y_true, y_pred)[1, 1] +\n",
    "                                                                            confusion_matrix(y_true, y_pred)[1, 0])\n",
    "\n",
    "\n",
    "def BER(y_true, y_pred): return 1-(0.5*(confusion_matrix(y_true, y_pred)[0, 0]/(confusion_matrix(y_true, y_pred)[0, 0] +\n",
    "                                                                                confusion_matrix(y_true, y_pred)[0, 1]) +\n",
    "                                        confusion_matrix(y_true, y_pred)[1, 1] / (\n",
    "                                        confusion_matrix(y_true, y_pred)[1, 1] +\n",
    "                                        confusion_matrix(y_true, y_pred)[1, 0])))\n",
    "\n",
    "\n",
    "clf = XGBClassifier(booster=\"gblinear\", n_estimators=500)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "tp = np.zeros(10)\n",
    "ber = np.zeros(10)\n",
    "tn = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_R = RFE(estimator=svm.SVR(kernel='linear', C=1), n_features_to_select=40, step=1)\n",
    "rfe = SelectFromModel(clf_R)\n",
    "select_k = SelectKBest(k=40)                         # other option mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for train_index, test_index in kf.split(data):\n",
    "    data_train, data_test = data[train_index], data[test_index]\n",
    "    target_train, target_test = target[train_index], target[test_index]\n",
    "    data_train = imputer.fit_transform(data_train)\n",
    "    ros = RandomUnderSampler(random_state=1)      # alternative ros = RandomOverSampler(random_state=1)\n",
    "    data_train, target_train = ros.fit_sample(data_train, target_train)\n",
    "    rfe = rfe.fit(data_train, target_train)\n",
    "    pipeline = Pipeline(steps=[('impute', imputer),\n",
    "                               ('var', low_Var),\n",
    "                               ('scale', scaler),\n",
    "                               ('FS', select_k),\n",
    "                               ('clf', clf)])\n",
    "\n",
    "    pipeline.fit(data_train, target_train)\n",
    "    predict = pipeline.predict(data_test)\n",
    "    ber[i] = BER(target_test, predict)\n",
    "    tp[i] = tp_rate(target_test, predict)\n",
    "    tn[i] = tn_rate(target_test, predict)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TP: %0.2f (+/- %0.2f)\" % (np.mean(tp),\n",
    "                                  np.std(tp) * 2))\n",
    "print(\"TN: %0.2f (+/- %0.2f)\" % (np.mean(tn),\n",
    "                                      np.std(tn) * 2))\n",
    "print(\"BER: %0.2f (+/- %0.2f)\" % (np.mean(ber),\n",
    "                                     np.std(ber) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
